{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "hack_df = pd.read_csv('train.csv')\n",
    "#hack_df.head(10)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "#test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Replacing 'year_built' NaN values with 2022 in test_df\n",
    "test_df['year_built'].fillna(2022, inplace=True)\n",
    "\n",
    "# List of columns to replace NaN values with their mean for test_df\n",
    "columns_to_replace_na = [\n",
    "    'energy_star_rating', \n",
    "    'direction_max_wind_speed', \n",
    "    'direction_peak_wind_speed',\n",
    "    'max_wind_speed',\n",
    "    'days_with_fog'\n",
    "]\n",
    "\n",
    "# Replacing NaN values in selected columns with their respective means in test_df\n",
    "for col in columns_to_replace_na:\n",
    "    test_df[col].fillna(test_df[col].mean(), inplace=True)\n",
    "\n",
    "# Splitting test_df into feature set and target\n",
    "x_test = test_df.iloc[:,4:62]\n",
    "y_test = test_df.iloc[:,62]\n",
    "\n",
    "# Displaying summary statistics and visualizing distribution of selected columns for test_df using Matplotlib\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 12))\n",
    "\n",
    "# Function to plot histogram and KDE\n",
    "def plot_hist_kde(data, ax, title, color='lightblue'):\n",
    "    # Histogram\n",
    "    ax.hist(data, bins=30, color=color, density=True, alpha=0.6)\n",
    "    # KDE\n",
    "    density = gaussian_kde(data)\n",
    "    xs = np.linspace(data.min(), data.max(), 200)\n",
    "    ax.plot(xs, density(xs), color='blue')\n",
    "    ax.set_title(title)\n",
    "\n",
    "plot_hist_kde(test_df['energy_star_rating'], axes[0, 0], 'Distribution of energy_star_rating')\n",
    "plot_hist_kde(test_df['direction_max_wind_speed'], axes[0, 1], 'Distribution of direction_max_wind_speed')\n",
    "plot_hist_kde(test_df['direction_peak_wind_speed'], axes[1, 0], 'Distribution of direction_peak_wind_speed')\n",
    "plot_hist_kde(test_df['max_wind_speed'], axes[1, 1], 'Distribution of max_wind_speed')\n",
    "plot_hist_kde(test_df['days_with_fog'], axes[2, 0], 'Distribution of days_with_fog')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-processing hack_df\n",
    "\n",
    "# Re-loading the datasets\n",
    "hack_df = pd.read_csv('train.csv')\n",
    "\n",
    "# List of columns to replace NaN values with their mean\n",
    "columns_to_replace_na = [\n",
    "    'energy_star_rating', \n",
    "    'direction_max_wind_speed', \n",
    "    'direction_peak_wind_speed',\n",
    "    'max_wind_speed',\n",
    "    'days_with_fog'\n",
    "]\n",
    "\n",
    "# Replacing 'year_built' NaN values with 2022 in hack_df\n",
    "hack_df['year_built'].fillna(2022, inplace=True)\n",
    "\n",
    "# Replacing NaN values in selected columns with their respective means in hack_df\n",
    "for col in columns_to_replace_na:\n",
    "    hack_df[col].fillna(hack_df[col].mean(), inplace=True)\n",
    "\n",
    "# Splitting hack_df into feature set and target\n",
    "x = hack_df.iloc[:,4:62]\n",
    "y = hack_df.iloc[:,62]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "x_training, x_testing, y_training, y_testing = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_training.shape, x_testing.shape, y_training.shape, y_testing.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Linear regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_training, y_training)\n",
    "\n",
    "#predicting the data\n",
    "lr_predictions = lr_model.predict(x_testing)\n",
    "\n",
    "#Calculating metrics\n",
    "lr_mse = mean_squared_error(y_testing, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_testing, lr_predictions)\n",
    "lr_r2 = r2_score(y_testing, lr_predictions)\n",
    "\n",
    "print('Linear Regression - Mean Squared Error:', lr_mse)\n",
    "print('Linear Regression - Mean Absolute Error:', lr_mae)\n",
    "print('Linear Regression - R2 Score:', lr_r2)\n",
    "\n",
    "#Drawwing the graph\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(y_testing, lr_predictions, alpha=0.4, color = 'green', marker='>')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--', lw=2, color='red')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Linear Regression Model Actual vs Predicted Values')\n",
    "plt.grid = True\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Decision Tree Regressor, R squared value for Linear Forest suggests that there can be imporvement in the model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=41)\n",
    "dt_model.fit(x_training, y_training)\n",
    "\n",
    "#predicting the data\n",
    "dt_predictions = dt_model.predict(x_testing)\n",
    "\n",
    "#calculating metrics\n",
    "dt_mse = mean_squared_error(y_testing, dt_predictions)\n",
    "dt_mae = mean_absolute_error(y_testing, dt_predictions)\n",
    "dt_r2 = r2_score(y_testing, dt_predictions)\n",
    "\n",
    "print('Decision Tree - Mean Squared Error:', dt_mse)\n",
    "print('Decision Tree - Mean Absolute Error:', dt_mae)\n",
    "print('Decision Tree - R2 Score:', dt_r2)\n",
    "\n",
    "#plotting the graph\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(y_testing, dt_predictions, alpha=0.6, color = 'green', marker='<')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--', lw=2, color='red')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Decision Tree Model Actual vs Predicted Values')\n",
    "plt.grid = True\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_training, y_training)\n",
    "\n",
    "# Predict on the testing data\n",
    "rf_predictions = rf_model.predict(x_testing)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rf_mae = mean_absolute_error(y_testing, rf_predictions)\n",
    "rf_mse = mean_squared_error(y_testing, rf_predictions)\n",
    "rf_r2 = r2_score(y_testing, rf_predictions)\n",
    "\n",
    "# Plotting actual vs predicted values for Random Forest\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_testing, rf_predictions, alpha=0.5, color=\"blue\")\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], '--', lw=2, color=\"red\")\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Random Forest Regressor: Actual vs Predicted')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "rf_mae, rf_mse, rf_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aniru\\Desktop\\dataTrain\\dataAnalyst2.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aniru/Desktop/dataTrain/dataAnalyst2.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m Ridge, Lasso\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aniru/Desktop/dataTrain/dataAnalyst2.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rid_model \u001b[39m=\u001b[39m Ridge(alpha\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aniru/Desktop/dataTrain/dataAnalyst2.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rid_model\u001b[39m.\u001b[39mfit(x_training, y_training)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_training' is not defined"
     ]
    }
   ],
   "source": [
    "#Ridge and Lasso Regression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "rid_model = Ridge(alpha=0.01, normalize=True)\n",
    "rid_model.fit(x_training, y_training)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
